<!DOCTYPE html>
<html lang="en">
<head>
  <title>activist.js design</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="http://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
</head>
<body class="container">
  <header>
    <h1>
      Activist.js: Design Doc
    </h1>
    <h4>
      <small>
        Will Scott (willscott@gmail.com)
      </small>
    </h4>
  </header>
  <section>
    <h2>Overview</h2>
    <p class="lead">
      Censorship is currently seen as a user problem. There are meaningful
      mitigation strategies that publishers can unilaterally deploy.
      The financial and reputation benefits have supported DDOS mitigation;
      why isn't censorship resistance a service?
    </p>
    <h3>Goals</h3>
    <dl class="dl-horizontal">
      <dt>Users</dt>
      <dd>Users should not notice that mitigation is in place until censorship
          occurs. At that point, they should be offered alternative mechanisms
          to access desired content, or ideally content should continue to be
          served despite network interference.
      </dd>
      <dt>Publishers</dt>
      <dd>Nontechnical publishers should be able to apply mitigation to their
          content. Mitigation should be as close to a single script tag as
          possible, and not require changes to publisher infrastructure, or
          frequent redeployment.
      </dd>
    </dl>
    <h3>Strategy</h3>
    <p>
      Using appCache, and forthcoming serviceWorkers, mitigated pages will
      cache logic for alternate content fetching techniques in the event of
      interference. These include:
    </p>
    <ul>
      <li>Delivery of existing tools like Tor</li>
      <li>Indirection of content through proxies</li>
      <li>Indirection of content through other clients</li>
    </ul>
    <h3>Implementation</h3>
    <p>
      activist.js will be delivered as a static javascript library for
      publishers. It will make it easy for users to get circumvention tools
      when they need them, by making sure they are actually pre-cached on disk.
    </p>
  </section>
  <section>
    <h2>Technical Objectives</h2>
    <ol>
      <li>Invisible
        <ol>
          <li>No noticeable page change for user</li>
          <li>No ongoing requirements from publishers</li>
          <li>Users have deniability of circumvention intent</li>
        </ol>
      </li>
      <li>Scalable
        <ol>
          <li>More publishers produce more collateral damage</li>
          <li>No centralized blockable entity</li>
        </ol>
      </li>
      <li>Private
        <ol>
          <li>Full list of participating sites should not be available</li>
          <li>Identification of other clients should not be possible</li>
        </ol>
      </li>
    </ol>
  </section>
  <section>
    <h2>Narrative</h2>
    A publisher will enable their domain via a code snippet equivalent to:
    <pre>
&lt;html <b>manifest='cache.manifest'</b>&gt;
  &lt;head&gt;
    <b>&lt;script type='text/javascript' src='activist.js'&gt;&lt;/script&gt;</b></pre>
    <p>
      Once in place, clients visiting the site will cache an appropriate
      circumvention binary in their browser cache, in case the site subsequently
      becomes unavailable.
    </p>
    <p>
      The initial version of activist.js will focus on providing access to the Tor Browser Bundle.
    </p>
    <p>
      On the first visit, activist.js will retrieve a set of ~5 other domains which also run the library, and load 5MB section of the current bundle (~25MB total) at each one (this is due to per-domain browser storage limits).  To  do this, it will load iframes for those domains, and connect to the other instances. Remember that these domains also will be cache manifest enabled, ensuring that the downloaded content remains accessible in the event of subsequent interference affecting multiple domains.
    </p>
    <p>
      If the domain is subsequently blocked, activist.js will prompt the user to use TorBrowser to get access to the content. They are then prompted for the 'unlimited storage' permission on their local domain.  Once that permission is granted, the chunks of the cached executable are reassembled into a single 'file'.  Signature check is performed against this reassembled version at this point.  A filesystem URL is then generated from the blob and used to extract the data to the installer for the user to download.
    </p>
  </section>
  <section>
    <h2>Activist.js Architecture</h2>
    <p>
      activist.js is structured as four modules
    </p>
    <dl>
      <dt>Liveness</dt>
      <dd>
        Determines current network state, and in particular if there is
        blocking of the current domain while other network activity is
        possible.
       </dd>
       <dt>Cache</dt>
       <dd>
         Fetches appropriate content and stores them in browser storage.
         Coordinates with other active domains to shard payloads too large
         to fit in a single cache.
       </dd>
       <dt>Coordinator</dt>
       <dd>
         Coordinates between activist.js enabled discovery of participants.
         Attempt signaling in the presence of infrastructure blocking.
       </dd>
       <dt>Interface</dt>
       <dd>
         Communicates blocking to the user, and offers mitigation strategies.
       </dd>
    </dl>
    <h3>Components</h3>
    <h4>Liveness</h4>
    <p>
      Determining the state of internet connection can be done by looking at
      navigator.onLine (which detects general connectivity) in tandem with
      checking XHR requests to the local domain, and a set of 'safe' domains.
    </p>
    <h4>Cache</h4>
    <p>
      The cache will use the FileSystem API, which typically is limited to 5MB.
      A larger file can be stored by using multiple top level domains.
      To reassemble the full payload into a single url the user must at the
      time of blocking approve a
      <a href='http://www.html5rocks.com/en/tutorials/file/filesystem/#toc-requesting-quota'>
        <code>requestQuota</code></a> call on one of the domains.
    </p>
    <h4>Coordinator</h4>
    <p>
      The coordinator does 2 things: Discovery of cooperating domains, and
      message passing between cooperating domains.
    </p>
    <p>
      In order to discover participating domains, we will initially use a
      private backend for coordination.  This allows us to do similar
      practical blocking mitigation as other one-hop circumvention systems.
    </p>
    <p>
      It is expected that this centralized infrastructure will be blocked
      in various countries. However, there remain a number of indirection
      channels which can be leveraged to increase the collateral damage
      associated with blocking them - for example STUN offers the ability
      to initiate a P2P connection setup, and the RESPONSE ADDRESS field
      allows the server's response to be indirected to the final destination,
      which can then delegate an unblocked machine to initiate connection back
      to the blocked user.
    </p>
    <p>
      For message passing, sites will add a known 'activistproxy.html' file
      on their domain to be opened in an iframe, which responds to messages
      passed by other participating domains. Domains will verify functionality
      of each other, as will the coordinator to ensure conformance to the
      protocol.
    </p>
    <h4>Interface</h4>
    <p>
      The interface will only display when a page is blocked, but needs to
      communicate to the user what has happened and what option activist.js is
      able to provide them to regain access to the content. Minimally, this
      needs to be some on-screen notification that the content they are viewing
      is state and served out of the app-cache due to network interference.
    </p>
  </section>
  <section>
    <h2>Threat Model</h2>
    <p>
      The adversary model is designed to largely express the powers of a
      state or ISP level actor. Activist.js is designed to tolerate an
      adversary with the following capabilities:
    </p>
    <ol>
      <li>Ability to block traffic using
        DNS Poisoning,
        IP Blacklist, or
        Protocol Blacklist.
      </li>
      <li>Ability to fingerprint traffic based on size and
        communication patterns.
      </li>
      <li>Unwilling to block all HTTPS Traffic.</li>
      <li>Unable to block on inspect HTTPS Traffic in realtime.</li>
    </ol>
    <h3>Attacks and Defenses</h3>
    <dl>
      <dt>Local DNS Poisoning</dt>
      <dd>
        If the local domain can't be reached, activist will be loaded by the
        cache, and can alert the user normally.
      </dd>
      <dt>Infrastructure DNS Poisoning</dt>
      <dd>
        If coordinators used by activist can't be reached, activist can attempt
        instead to initiate a WebRTC connection, using known stun server to
        alert a watching party of its presence. This works by faking the
        SIP answer to come from the well known destination, and when the
        connection can not be made directly, signalling will occur via
        intermediary stun and turn server. Upon learning of a peer, the
        coordinator can either forge packets in response, (or use a TURN
        relay) to communicate back alternative connection means.  Potentially,
        this could take the form of an unblocked client, who would only
        participate transiently in the exchange.  The complexity of this
        response is expected to develop over time as the capabilities of
        the protocols involve stabalize.
      </dd>
      <dt>IP Blocking</dt>
      <dd>
        Will Be handled in the same way as DNS Poisoning above.
      </dd>
      <dt>Blocking of other sites</dt>
      <dd>
        Potentially a smaller target can be used which fits in
        the single domain 5MB space.
      </dd>
      <dt>Crawling of participating sites</dt>
      <dd>
        short lists can be given out, including sites controlled
        by the coordinator who can track for crawling behavior.
        When crawling is distributed across many IP addresses,
        WebRTC communication against supposidly 'blocked' nodes
        can be used to help detect if new sites are really needed.
      </dd>
    </dl>
  </section>
</body>
</html>
